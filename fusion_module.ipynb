{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc3cac-bfa2-4129-8870-abd62b34dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import anndata as ad\n",
    "\n",
    "# 设备配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----------------------\n",
    "# 数据预处理\n",
    "# ----------------------\n",
    "\n",
    "# 提取原始数据\n",
    "gex_data = data['gex'].X  # 原始基因表达矩阵\n",
    "if sp.issparse(gex_data):\n",
    "    gex_data = gex_data.toarray()\n",
    "\n",
    "immune_data = data['gex'].obsm['X_immune']  # 免疫组数据\n",
    "\n",
    "# 计算基因表达数据的文库大小 (用于ZINB损失)\n",
    "library_size = gex_data.sum(axis=1)\n",
    "log_library_size = np.log(library_size).reshape(-1, 1)\n",
    "\n",
    "# 归一化免疫组数据\n",
    "scaler_immune = StandardScaler()\n",
    "normalized_immune = scaler_immune.fit_transform(immune_data)\n",
    "\n",
    "# 基因表达数据预处理\n",
    "# 使用log(CPM+1)转换\n",
    "cpm = gex_data / library_size[:, None] * 1e4\n",
    "log_cpm = np.log1p(cpm)\n",
    "scaler_gex = StandardScaler()\n",
    "normalized_gex = scaler_gex.fit_transform(log_cpm)\n",
    "\n",
    "# 拼接输入特征\n",
    "input_features = np.concatenate([normalized_gex, normalized_immune], axis=1)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "X = torch.tensor(input_features, dtype=torch.float32)\n",
    "X_immune = torch.tensor(normalized_immune, dtype=torch.float32)\n",
    "X_gex = torch.tensor(gex_data, dtype=torch.float32)  # 原始计数用于ZINB损失\n",
    "libsize = torch.tensor(log_library_size, dtype=torch.float32)\n",
    "\n",
    "# 创建数据集\n",
    "dataset = TensorDataset(X, X_gex, X_immune, libsize)\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128)\n",
    "\n",
    "# ----------------------\n",
    "# 网络架构\n",
    "# ----------------------\n",
    "\n",
    "def build_multi_layers(layers, dropout_rate=0.1):\n",
    "    \"\"\"构建多层感知器\"\"\"\n",
    "    modules = []\n",
    "    for i in range(len(layers) - 1):\n",
    "        modules.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "        modules.append(nn.BatchNorm1d(layers[i + 1]))\n",
    "        modules.append(nn.ELU())\n",
    "        modules.append(nn.Dropout(p=dropout_rate))\n",
    "    return nn.Sequential(*modules)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器网络\"\"\"\n",
    "    def __init__(self, input_dim, layer_dims, z_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        if layer_dims:\n",
    "            self.base = build_multi_layers([input_dim] + layer_dims, dropout_rate)\n",
    "        else:\n",
    "            self.base = nn.Identity()\n",
    "            \n",
    "        in_dim = layer_dims[-1] if layer_dims else input_dim\n",
    "        self.fc_mean = nn.Linear(in_dim, z_dim)\n",
    "        self.fc_logvar = nn.Linear(in_dim, z_dim)\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mean + eps * std\n",
    "        return mean\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.base(x)\n",
    "        mean = self.fc_mean(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        return z, mean, logvar\n",
    "\n",
    "class ZINBDecoder(nn.Module):\n",
    "    \"\"\"ZINB解码器用于基因表达重构\"\"\"\n",
    "    def __init__(self, z_dim, layer_dims, output_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        if layer_dims:\n",
    "            self.base = build_multi_layers([z_dim] + layer_dims, dropout_rate)\n",
    "        else:\n",
    "            self.base = nn.Identity()\n",
    "            \n",
    "        in_dim = layer_dims[-1] if layer_dims else z_dim\n",
    "        self.scale_decoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, output_dim),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.disp_decoder = nn.Linear(in_dim, output_dim)\n",
    "        self.dropout_decoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, library):\n",
    "        h = self.base(z)\n",
    "        scale = self.scale_decoder(h)\n",
    "        dispersion = torch.exp(self.disp_decoder(h)) + 1e-8\n",
    "        dropout_rate = self.dropout_decoder(h)\n",
    "        \n",
    "        # 重构基因表达\n",
    "        recon = torch.exp(library) * scale\n",
    "        return {\n",
    "            'scale': scale,\n",
    "            'dispersion': dispersion,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'recon': recon\n",
    "        }\n",
    "\n",
    "class ImmuneDecoder(nn.Module):\n",
    "    \"\"\"免疫组数据解码器\"\"\"\n",
    "    def __init__(self, z_dim, layer_dims, output_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        if layer_dims:\n",
    "            layers = [z_dim] + layer_dims + [output_dim]\n",
    "            self.decoder = build_multi_layers(layers, dropout_rate)\n",
    "        else:\n",
    "            self.decoder = nn.Linear(z_dim, output_dim)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "# ----------------------\n",
    "# 损失函数\n",
    "# ----------------------\n",
    "\n",
    "class ZINBLoss(nn.Module):\n",
    "    def __init__(self, ridge_lambda=0.0):\n",
    "        super().__init__()\n",
    "        self.ridge_lambda = ridge_lambda\n",
    "        \n",
    "    def forward(self, x, recon_dict):\n",
    "        scale = recon_dict['scale']\n",
    "        disp = recon_dict['dispersion']\n",
    "        pi = recon_dict['dropout_rate']\n",
    "        eps = 1e-10\n",
    "        \n",
    "        mean = recon_dict['recon']\n",
    "        t1 = torch.lgamma(disp + eps) + torch.lgamma(x + 1.0) - torch.lgamma(x + disp + eps)\n",
    "        t2 = (disp + x) * torch.log(1.0 + (mean / (disp + eps))) + (x * (torch.log(disp + eps) - torch.log(mean + eps)))\n",
    "        nb_final = t1 + t2\n",
    "        \n",
    "        nb_case = nb_final - torch.log(1.0 - pi + eps)\n",
    "        zero_nb = torch.pow(disp / (disp + mean + eps), disp)\n",
    "        zero_case = -torch.log(pi + ((1.0 - pi) * zero_nb) + eps)\n",
    "        result = torch.where(x < 1e-8, zero_case, nb_case)\n",
    "        \n",
    "        ridge = self.ridge_lambda * torch.square(pi)\n",
    "        result += ridge\n",
    "        \n",
    "        return torch.mean(result)\n",
    "\n",
    "class KLDivergenceLoss(nn.Module):\n",
    "    \"\"\"KL散度损失\"\"\"\n",
    "    def forward(self, mean, logvar):\n",
    "        return -0.5 * torch.mean(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "\n",
    "# ----------------------\n",
    "# 整体VAE模型\n",
    "# ----------------------\n",
    "\n",
    "class MultiModalVAE(nn.Module):\n",
    "    def __init__(self, gex_dim, immune_dim, latent_dim, \n",
    "                 enc_layers, gex_dec_layers, immune_dec_layers):\n",
    "        super().__init__()\n",
    "        input_dim = gex_dim + immune_dim\n",
    "        \n",
    "        # 子模块\n",
    "        self.encoder = Encoder(input_dim, enc_layers, latent_dim)\n",
    "        self.gex_decoder = ZINBDecoder(latent_dim, gex_dec_layers, gex_dim)\n",
    "        self.immune_decoder = ImmuneDecoder(latent_dim, immune_dec_layers, immune_dim)\n",
    "        \n",
    "    def forward(self, x, libsize):\n",
    "        z, mean, logvar = self.encoder(x)\n",
    "        gex_output = self.gex_decoder(z, libsize)\n",
    "        immune_recon = self.immune_decoder(z)\n",
    "        return gex_output, immune_recon, z, mean, logvar\n",
    "\n",
    "# ----------------------\n",
    "# 训练配置\n",
    "# ----------------------\n",
    "\n",
    "# 设置超参数\n",
    "config = {\n",
    "    'gex_dim': normalized_gex.shape[1],\n",
    "    'immune_dim': normalized_immune.shape[1],\n",
    "    'latent_dim': 20,\n",
    "    'enc_layers': [256, 128],\n",
    "    'gex_dec_layers': [128, 256],\n",
    "    'immune_dec_layers': [64],\n",
    "    'weights': {\n",
    "        'gex':1,\n",
    "        'immune': 0.1,\n",
    "        'kl': 0.001\n",
    "    },\n",
    "    'lr': 1e-3,\n",
    "    'epochs': 50\n",
    "}\n",
    "\n",
    "# 初始化模型\n",
    "model = MultiModalVAE(\n",
    "    gex_dim=config['gex_dim'],\n",
    "    immune_dim=config['immune_dim'],\n",
    "    latent_dim=config['latent_dim'],\n",
    "    enc_layers=config['enc_layers'],\n",
    "    gex_dec_layers=config['gex_dec_layers'],\n",
    "    immune_dec_layers=config['immune_dec_layers']\n",
    ").to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion_zinb = ZINBLoss()\n",
    "criterion_immune = nn.MSELoss()\n",
    "criterion_kl = KLDivergenceLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=1e-5)\n",
    "\n",
    "# ----------------------\n",
    "# 训练循环\n",
    "# ----------------------\n",
    "\n",
    "def train(model, dataloader, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        X_batch, X_gex_batch, X_immune_batch, lib_batch = batch\n",
    "        X_batch, X_gex_batch, X_immune_batch, lib_batch = \\\n",
    "            X_batch.to(device), X_gex_batch.to(device), \\\n",
    "            X_immune_batch.to(device), lib_batch.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        gex_output, immune_recon, _, mean, logvar = model(X_batch, lib_batch)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss_gex = criterion_zinb(X_gex_batch, gex_output)\n",
    "        loss_immune = criterion_immune(immune_recon, X_immune_batch)\n",
    "        loss_kl = criterion_kl(mean, logvar)\n",
    "        \n",
    "        # 加权总损失\n",
    "        total_batch_loss = (\n",
    "            config['weights']['gex'] * loss_gex +\n",
    "            config['weights']['immune'] * loss_immune +\n",
    "            config['weights']['kl'] * loss_kl\n",
    "        )\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        total_batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += total_batch_loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# 训练主循环\n",
    "train_losses = []\n",
    "for epoch in range(config['epochs']):\n",
    "    loss = train(model, train_loader, optimizer, epoch)\n",
    "    train_losses.append(loss)\n",
    "    print(f'Epoch [{epoch+1}/{config[\"epochs\"]}], Loss: {loss:.4f}')\n",
    "\n",
    "# 绘制训练损失\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_loss.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mosaicenv]",
   "language": "python",
   "name": "conda-env-mosaicenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
